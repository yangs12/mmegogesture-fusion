_wandb:
    value:
        cli_version: 0.19.10
        m: []
        python_version: 3.10.16
        t:
            "1":
                - 1
                - 5
                - 29
                - 41
                - 50
                - 53
                - 55
            "2":
                - 1
                - 5
                - 29
                - 41
                - 50
                - 53
                - 55
            "3":
                - 13
                - 16
                - 23
                - 55
                - 61
            "4": 3.10.16
            "5": 0.19.10
            "8":
                - 5
            "12": 0.19.10
            "13": linux-x86_64
fusion:
    value:
        fusion_level: multi
        fusion_mode: cross
model:
    value:
        backbone: mobilenet-2D
        fusion: multi_cross
preprocess:
    value:
        flag_statistics: true
        flag_visualize: false
project:
    value: gesture_attention
result:
    value:
        classes:
            - 06.Click
            - 05.FSnap
            - 04.ZIn
            - 07.Knock
            - 08.SwpL
            - 09.SwpR
            - 10.T_ZIn
            - 11.T_ZOut
            - 12.Stop
            - 01.OK
            - 03.TmbUp
            - 02.Photo
        labels:
            - "1"
            - "2"
            - "3"
            - "4"
            - "5"
            - "6"
            - "7"
            - "8"
            - "9"
            - "10"
            - "11"
            - "12"
        name: jchang-gesture_attention-epoch100
        note: Temp
        path_data: /bigdata/shuboy/mm-egogesture/Gesture_processed_public
        path_des: /home/jchang13/fusion/mmegogesture-fusion/downloads/Metadata/des_public.csv
        path_save_vis: /home/jchang13/fusion/mmegogesture-fusion/vis_outputs
        save_model: false
        save_vis: false
sensor:
    value:
        fps_cam: 30
        select:
            - rad-uD
            - cam-img
        t_snapshot: 2.667
        win_cam: 80
        win_rad: 512
train:
    value:
        batch_size: 16
        delta: 0.01
        epoch: 100
        learning_rate: 0.0001
        n_class: 12
        num_workers: 4
        pretrain: true
        traintest_split: subject-3_4_5
        weight_decay: 0.01
transforms:
    value:
        cropratio_uD: 1
        mean_std:
            cam-img:
                - - 0.4125
                  - 0.1556
                - - 0.4229
                  - 0.149
                - - 0.4251
                  - 0.1561
            cam-vid:
                - - 0.4125
                  - 0.1556
                - - 0.4229
                  - 0.149
                - - 0.4251
                  - 0.1561
            rad-A:
                - 40.2172
                - 7.3238
            rad-D:
                - 46.6549
                - 23.3134
            rad-R:
                - 52.2055
                - 4.7976
            rad-uD:
                - 8.209
                - 6.3781
            rad-uD_Wdouble:
                - 5.0373
                - 6.2107
            rad-uD_Whalf:
                - 11.5463
                - 6.8219
            rad-uD_channel:
                - 7.6703
                - 7.2454
        resample_cam: 16
        size_cam: 256
        size_rad_D: 256
        size_rad_T: 512
        t_actual: 1.6
        t_spare: 0.2
wandb:
    value:
        log_all: false
        project: Gesture_attention
        use_wandb: true
